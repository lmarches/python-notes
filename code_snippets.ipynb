{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code-snippets.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmarches/python-notes/blob/master/code_snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guHTB6SVOR74",
        "colab_type": "text"
      },
      "source": [
        "# Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0irOtPGPOW2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove duplicate rows by\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFOYrx2Ny3Q5",
        "colab_type": "text"
      },
      "source": [
        "## Creating Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy1x4L16zPYk",
        "colab_type": "text"
      },
      "source": [
        "Header below requires the following libraries installed: \n",
        "- plotly \n",
        "- seaboarn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRavOK05zK2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from datetime import datetime\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "from plotly import __version__\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.height', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsWExsSwbecP",
        "colab_type": "text"
      },
      "source": [
        "# Text manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96qtzDgvcRuN",
        "colab_type": "text"
      },
      "source": [
        "## Date Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEyL5zSbcR_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "date = datetime.datetime(2012,9,23,0,0,5)\n",
        "date += datetime.timedelta(days=1)\n",
        "date += datetime.timedelta(hours=5)\n",
        "str(date)\n",
        "\n",
        "date.strftime('We are the %d, %b %Y')\n",
        "datetime.datetime(2020, 1, 16, 11, 0)\n",
        "\n",
        "# date.strftime('We are the %d, %b %Y')\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "start_date = datetime.strptime(\"13/02/2020\",\"%d/%m/%Y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYBANMoqSWDy",
        "colab_type": "text"
      },
      "source": [
        "### Get links from excel tables exported into a html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOSZ6wdoSclu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import pandas as pd\n",
        "\n",
        "f = open('Book1.htm')\n",
        "page =f.read()\n",
        "df = pd.DataFrame(columns=['URLS'],\n",
        "             data= re.findall('href=\\\"(.*)\" target=\\\"_blank\\\">',page))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNAringGao6H",
        "colab_type": "text"
      },
      "source": [
        "### Convert GoodReader highlights into table\n",
        "\n",
        "1. Upload files of raw highlights to the corresponding document into the [notion table](https://www.notion.so/lucamarchesotti/8185a2a4922e443f9db36298c7abad87?v=0a3ce78abfe843558d454c5da1941fb2)\n",
        "2. Copy URL below \n",
        "3. Download the highlights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83qxZvkeocP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import pandas as pd\n",
        "\n",
        "import urllib2\n",
        "\n",
        "url_file = 'https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d2a49650-9b69-44b3-9cc0-34c6fe238da0/comments.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAT73L2G45LRRU65I2%2F20190424%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20190424T110804Z&X-Amz-Expires=86400&X-Amz-Security-Token=AgoJb3JpZ2luX2VjEPn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQC2ItMJQdv5jzYde0osp0msiV4Iw1cNV%2BespwEHGj%2BTQwIgTrDjOwQjYqI%2FOuHaPYqBEoejxwqJx5bSkhbE6rJrXF8q4wMI0v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgwyNzQ1NjcxNDkzNzAiDBfOKsl%2FN5OXFtbEYCq3A43j4AFbwPM4bsLRQRRCh8hWj10MEqFxRvbb3uMsmyHFsI6LGuaKr9au58uZJ663dB05AU8pxyiVB2%2BG3rLCRKNa8j2Fv42QEOpqbNBsmXRkhwsNKQW6rTX10%2Flk8ClSRFXqpmyhT1gFHus7GC58Um5zik0IUIuUgHf8Q38pFiMbqHXydp0ltTAFaVKIfF6xFH4S%2FNpfjbRKCMNBKKa6DKMsbJRcqdF3Ar6RHfXjRYGzr73oW58vPBCdAsbJjOu51FEpg5gFjR6KZSuDLmnj4kVmUJebnHW5GlP4FZulLz9FSQXWp6qYLY76oDuBMMGTg9jTeeXZhAAR7GQqeE1U0l52qgGzdey9yyXFqDnp1ub0Gt98RDrxKspYDh%2BbMBjv9njZmXniB5lqCkTLu4aaADJkrXGYRGk5kaTW9yKVZ2kBcPywwSSJ8%2B%2Bt4qKeKyIuAdyVc7LWwbVDNuuqLdbDSdVNY0s1JKVrQqaOQ9kp8DqEQp5E%2FGJqBurB5cYFudXg3S8ypkV1jDsJiVlVjIWMZsI4Kz8gfTxk65qdzxnsRNPbo6eFmDEr6hnx5wa1413hYDWlUienj1kwgruA5gU6tAHMDq%2BfibSnT40i00ad83MYmArKI2l%2B1Si2Nmcppjev%2BgrErlX4C01%2FrJR7R%2BZ90WuWnRod0N3EAhNdVDEvPiwCRIEwM7k9%2FY1suOX%2FJKOIqH5mTZNRL0ECjQZ0DadqbwtNBIXc9gEGQmy3tzcs4urffE2a5LLzFDzJdv8%2BJFjO7MMY6jDlpsMMgiWXVMGVly4wemwTKa3zfddGcIy8lxzGgzDz7GyqjC%2FuUn%2BZQu9lGg0RP90%3D&X-Amz-Signature=9751c38ee42a05d057a361294f1db0089d0111e8aee974758a7de447901f0326&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22comments.txt%22'\n",
        "\n",
        "response = urllib2.urlopen(url_file)\n",
        "\n",
        "page =response.readlines()\n",
        "\n",
        "\n",
        "highlightgs = []\n",
        "page_numbers = []\n",
        "page_number = 0 \n",
        "\n",
        "for l in page: \n",
        "    if not(re.match('Highlight ',l)): \n",
        "        if re.match('---(.*?)---',l):\n",
        "            page_number = re.findall('--- Page (.*?) ---',l)[0]\n",
        "        else:\n",
        "            if l !='\\n':\n",
        "                highlightgs.append(l)\n",
        "                page_numbers.append(page_number)\n",
        "            \n",
        "highlights_table = pd.DataFrame(columns=['highlights','page_numbers'])\n",
        "\n",
        "highlights_table['highlights'] = highlightgs\n",
        "highlights_table['page_numbers'] = page_numbers\n",
        "highlights_table.to_csv('highlights.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLnQH9eaeuuM",
        "colab_type": "text"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mXbiclZDh12",
        "colab_type": "text"
      },
      "source": [
        "### Safe crawling with Urllib 2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiyTPAWwd63i",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title\n",
        "import re \n",
        "\n",
        "import urllib, json, urllib2\n",
        "import socket\n",
        "\n",
        "\n",
        "urllib_timeout = 5\n",
        "\n",
        "def crawl(url): \n",
        "    # if this does not work check out the following\n",
        "    # http://stackoverflow.com/questions/9276243/python-urllib2-timeout?rq=1\n",
        "    # timeout in seconds\n",
        "    socket.setdefaulttimeout(urllib_timeout)\n",
        "    try:\n",
        "        req = urllib2.Request(url, headers={ 'User-Agent': 'Mozilla/5.0' })\n",
        "        data = urllib2.urlopen(req).read()\n",
        "\n",
        "            # timeout=urllib_timeout)\n",
        "    except Exception,e:\n",
        "        print '[ERROR]:'+ str(type(e))    #not catch\n",
        "        return 0\n",
        "    except urllib2.URLError as e:\n",
        "        print '[ERROR]:'+ str(type(e))    #not catch\n",
        "        return 0\n",
        "    except socket.timeout as e:\n",
        "        print '[ERROR]:'+ str(type(e))    #catched\n",
        "        return 0\n",
        "    \n",
        "    return data#code snapshot\n",
        "\n",
        "\n",
        "  \n",
        "#   <div class=\"psf-partner-name\"><a href=\"/partners/find/partnerdetails/?n=ECS&amp;id=001E000000Rp5FUIAZ\">ECS</a></div>\n",
        "  \n",
        "  \n",
        "  \n",
        "page = crawl(\"https://aws.amazon.com//partners/find/partnerdetails/?n=ECS&amp;id=001E000000Rp5FUIAZ\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJLB8Y0B9jU4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "import re\n",
        "tags = re.findall(r'\\B(\\#[A-Za-z]+\\b)', input_data['rawText'])\n",
        "text = input_data['rawText'].split('#')[0]\n",
        "\n",
        "channelName_parsed = input_data['channelName'].split('-')[-1]\n",
        "output = [{'category': tags[0][3:] if tags else None, 'type': tags[1][3:] if len(tags)>1 else None, 'tag3': tags[2][3:] if len(tags)>2 else None,'body': text, 'channelName_parsed': channelName_parsed}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3CyHq-GXDoQ",
        "colab_type": "text"
      },
      "source": [
        "# Bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqeqOGd_bNu2",
        "colab_type": "text"
      },
      "source": [
        "### Batch rename "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEmepfm4XHKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "echo \"file_src,file_dst\" > DS06-seedling-root-selection-for-annotation.log; c=0; for f in *.png; do new_f=$(printf \"images-and-masks-%04d.png\" $c);  echo $f,$new_f; cp $f $new_f; c=$((c+1)) ; done >> DS06-seedling-root-selection-for-annotation.log"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}